# ğŸš€ Ubelixé›†ç¾¤GPUä½¿ç”¨å®Œæ•´æ•™ç¨‹

## ğŸ“‹ ç›®å½•
- [GPUèµ„æºç”³è¯·æ–¹å¼](#gpuèµ„æºç”³è¯·æ–¹å¼)
- [äº¤äº’å¼ä¼šè¯ä½¿ç”¨](#äº¤äº’å¼ä¼šè¯ä½¿ç”¨)
- [æ‰¹å¤„ç†ä½œä¸šæäº¤](#æ‰¹å¤„ç†ä½œä¸šæäº¤)
- [ä»»åŠ¡çŠ¶æ€ç›‘æ§](#ä»»åŠ¡çŠ¶æ€ç›‘æ§)
- [æ—¥å¿—æŸ¥çœ‹å’Œè°ƒè¯•](#æ—¥å¿—æŸ¥çœ‹å’Œè°ƒè¯•)
- [èµ„æºç®¡ç†å’Œä¼˜åŒ–](#èµ„æºç®¡ç†å’Œä¼˜åŒ–)
- [å¸¸è§é—®é¢˜è§£å†³](#å¸¸è§é—®é¢˜è§£å†³)
- [æœ€ä½³å®è·µå»ºè®®](#æœ€ä½³å®è·µå»ºè®®)

---

## GPUèµ„æºç”³è¯·æ–¹å¼

### ğŸ¯ ä¸¤ç§ä¸»è¦æ–¹å¼

#### 1. äº¤äº’å¼ä¼šè¯ (Interactive Session)
**ç‰¹ç‚¹ï¼š** ç›´æ¥åœ¨GPUèŠ‚ç‚¹ä¸Šè·å¾—shellè®¿é—®ï¼Œé€‚åˆå¼€å‘ã€è°ƒè¯•ã€æµ‹è¯•

#### 2. æ‰¹å¤„ç†ä½œä¸š (Batch Job)
**ç‰¹ç‚¹ï¼š** æäº¤è„šæœ¬åˆ°é˜Ÿåˆ—ï¼Œåå°è¿è¡Œï¼Œé€‚åˆé•¿æ—¶é—´è®­ç»ƒ

---

## äº¤äº’å¼ä¼šè¯ä½¿ç”¨

### ğŸ“ å¿«é€Ÿå¯åŠ¨è„šæœ¬

æœ¬é¡¹ç›®æä¾›äº†ä¸‰ç§é¢„é…ç½®çš„äº¤äº’å¼ä¼šè¯è„šæœ¬ï¼š

```bash
# æ™ºèƒ½é€‰æ‹©è„šæœ¬ï¼ˆæ¨èæ–°ç”¨æˆ·ï¼‰
./Setup/H100.sh

# ç›´æ¥å¯åŠ¨ç‰¹å®šQoSä¼šè¯
./Setup/interactive_job_interactive.sh          # æ ‡å‡†äº¤äº’å¼
./Setup/interactive_job_gpu_preemptable.sh      # æ¨èï¼šæˆåŠŸç‡æœ€é«˜
./Setup/interactive_job_gpu_debug.sh            # å¿«é€Ÿè°ƒè¯•ï¼ˆ20åˆ†é’Ÿé™åˆ¶ï¼‰
```

### ğŸ”§ æ‰‹åŠ¨å‘½ä»¤æ ¼å¼

```bash
srun --partition=<åˆ†åŒº> --qos=<QoS> --gpus=<GPUç±»å‹>:<æ•°é‡> \
     --cpus-per-task=<CPUæ•°> --mem=<å†…å­˜> --time=<æ—¶é—´é™åˆ¶> --pty bash
```

### ğŸ“Š QoSç­–ç•¥å¯¹æ¯”

| QoSç±»å‹ | ä¼˜å…ˆçº§ | æ—¶é—´é™åˆ¶ | åˆ†åŒº | ç‰¹ç‚¹ | æ¨èåœºæ™¯ |
|---------|--------|----------|------|------|----------|
| `job_interactive` | 50 | 8å°æ—¶ | gpu | æ ‡å‡†äº¤äº’å¼ | æ—¥å¸¸å¼€å‘ |
| `job_gpu_preemptable` | 0 | 1å¤© | gpu-invest | å¯æŠ¢å ï¼ŒæˆåŠŸç‡é«˜ | **æ¨èä½¿ç”¨** |
| `job_gpu_debug` | 50 | 20åˆ†é’Ÿ | gpu | å¿«é€Ÿè·å¾—èµ„æº | å¿«é€Ÿæµ‹è¯• |

### âœ… äº¤äº’å¼ä¼šè¯æˆåŠŸå

```bash
# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# æ£€æŸ¥CUDAç‰ˆæœ¬
nvcc --version

# æ¿€æ´»condaç¯å¢ƒ
conda activate your_env

# è¿è¡ŒPythonè„šæœ¬
python your_script.py

# å®æ—¶ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi
```

---

## æ‰¹å¤„ç†ä½œä¸šæäº¤

### ğŸ“„ SLURMè„šæœ¬ç¤ºä¾‹

```bash
#!/usr/bin/env bash
#SBATCH --job-name=my_training
#SBATCH --partition=gpu-invest
#SBATCH --qos=job_gpu_preemptable
#SBATCH --gpus=h100:1
#SBATCH --cpus-per-task=4
#SBATCH --mem=90G
#SBATCH --time=08:00:00
#SBATCH --output=logs/%x-%j.out
#SBATCH --error=logs/%x-%j.err

# æ¿€æ´»ç¯å¢ƒ
conda activate your_env

# è¿è¡Œè®­ç»ƒè„šæœ¬
python train.py --epochs 100 --batch-size 32
```

### ğŸš€ æäº¤å’Œç®¡ç†

```bash
# æäº¤ä½œä¸š
sbatch your_script.sbatch

# å–æ¶ˆä½œä¸š
scancel <JOB_ID>

# æŸ¥çœ‹ä½œä¸šè¯¦æƒ…
scontrol show job <JOB_ID>

# æŸ¥çœ‹ä½œä¸šå†å²
sacct -j <JOB_ID> --format=JobID,JobName,State,ExitCode,Start,End,Elapsed
```

---

## ä»»åŠ¡çŠ¶æ€ç›‘æ§

### ğŸ” åŸºç¡€æŸ¥çœ‹å‘½ä»¤

```bash
# æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡
squeue -u $USER

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
squeue -u $USER --format="%.10i %.12P %.20j %.10u %.2t %.10M %.5D %.20R"

# æŸ¥çœ‹ç‰¹å®šåˆ†åŒºçš„ä»»åŠ¡
squeue -p gpu-invest

# å®æ—¶ç›‘æ§
watch -n 5 'squeue -u $USER'
```

### ğŸ“Š ä»»åŠ¡çŠ¶æ€å«ä¹‰

| çŠ¶æ€ | å«ä¹‰ | è¯´æ˜ |
|------|------|------|
| `PD` | Pending | ç­‰å¾…èµ„æºåˆ†é… |
| `R` | Running | æ­£åœ¨è¿è¡Œ |
| `CG` | Completing | å³å°†å®Œæˆ |
| `CD` | Completed | å·²å®Œæˆ |
| `F` | Failed | å¤±è´¥ |
| `CA` | Cancelled | å·²å–æ¶ˆ |

### ğŸš¨ å¸¸è§ç­‰å¾…åŸå› 

| åŸå›  | è§£é‡Š | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| `(QOSGrpGRES)` | QoSèµ„æºé™åˆ¶ | å°è¯•å…¶ä»–QoSæˆ–å‡å°‘èµ„æºè¯·æ±‚ |
| `(Resources)` | èµ„æºä¸è¶³ | ç­‰å¾…æˆ–å‡å°‘èµ„æºéœ€æ±‚ |
| `(Priority)` | ä¼˜å…ˆçº§ä½ | ä½¿ç”¨æ›´é«˜ä¼˜å…ˆçº§çš„QoS |
| `(QOSMaxGRESPerUser)` | ç”¨æˆ·èµ„æºé™åˆ¶ | ç­‰å¾…å…¶ä»–ä»»åŠ¡å®Œæˆ |

---

## æ—¥å¿—æŸ¥çœ‹å’Œè°ƒè¯•

### ğŸ“ æ—¥å¿—æ–‡ä»¶ä½ç½®

```bash
# SLURMè‡ªåŠ¨ç”Ÿæˆçš„æ—¥å¿—
logs/your_job_name-<JOB_ID>.out    # æ ‡å‡†è¾“å‡º
logs/your_job_name-<JOB_ID>.err    # é”™è¯¯è¾“å‡º

# è‡ªå®šä¹‰æ—¥å¿—ç›®å½•
logs_training/
tensorboard_logs/
checkpoints/
```

### ğŸ”§ å®æ—¶æ—¥å¿—ç›‘æ§

```bash
# å®æ—¶æŸ¥çœ‹è¾“å‡ºæ—¥å¿—
tail -f logs/your_job-12345.out

# å®æ—¶æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/your_job-12345.err

# æŸ¥çœ‹æœ€è¿‘çš„æ—¥å¿—å†…å®¹
tail -100 logs/your_job-12345.out

# æœç´¢æ—¥å¿—ä¸­çš„å…³é”®è¯
grep -n "error\|Error\|ERROR" logs/your_job-12345.err
grep -n "loss\|accuracy" logs/your_job-12345.out
```

### ğŸ“Š TensorBoardç›‘æ§ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

```bash
# åœ¨äº¤äº’å¼ä¼šè¯ä¸­å¯åŠ¨TensorBoard
tensorboard --logdir=./logs_training --host=0.0.0.0 --port=6006

# é€šè¿‡SSHéš§é“è®¿é—®
ssh -L 6006:localhost:6006 user@submit03.unibe.ch
# ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—® http://localhost:6006
```

---

## èµ„æºç®¡ç†å’Œä¼˜åŒ–

### ğŸ’¾ å­˜å‚¨ç®¡ç†

```bash
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨
du -sh * | sort -hr

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
find . -name "*.tmp" -delete
find . -name "__pycache__" -type d -exec rm -rf {} +

# å‹ç¼©å¤§æ–‡ä»¶
tar -czf archive_name.tar.gz folder_to_compress/
```

### ğŸ”‹ GPUèµ„æºæŸ¥çœ‹

```bash
# å½“å‰GPUä½¿ç”¨æƒ…å†µ
gpu-usage

# æŸ¥çœ‹å¯ç”¨GPUç±»å‹
sinfo -p gpu --Format=partition,avail,nodes,gres

# æ£€æŸ¥GPUèŠ‚ç‚¹çŠ¶æ€
sinfo -p gpu-invest -N -o "%N %G %C %m %e %T"
```

### âš¡ æ€§èƒ½ç›‘æ§

```bash
# GPUç›‘æ§è„šæœ¬ï¼ˆä¿å­˜ä¸ºmonitor_gpu.shï¼‰
#!/bin/bash
while true; do
    echo "=== $(date) ==="
    nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv
    echo ""
    sleep 10
done
```

---

## å¸¸è§é—®é¢˜è§£å†³

### â“ Q1: ä»»åŠ¡ä¸€ç›´åœ¨ç­‰å¾…é˜Ÿåˆ—ä¸­
```bash
# æ£€æŸ¥ä»»åŠ¡ç­‰å¾…åŸå› 
squeue -j <JOB_ID> --format="%.18i %.20P %.8j %.8u %.8T %.19S %.6D %.20R %Q"

# è§£å†³æ–¹æ¡ˆ
1. å°è¯•å…¶ä»–QoS: job_gpu_preemptable
2. å‡å°‘èµ„æºè¯·æ±‚ï¼ˆå†…å­˜ã€GPUæ•°é‡ï¼‰
3. é€‰æ‹©ä¸åŒæ—¶é—´æ®µæäº¤
4. ä½¿ç”¨gpu-investåˆ†åŒº
```

### â“ Q2: äº¤äº’å¼ä¼šè¯è¿æ¥æ–­å¼€
```bash
# ä½¿ç”¨screenæˆ–tmuxä¿æŒä¼šè¯
screen -S gpu_session
# æˆ–
tmux new-session -s gpu_session

# æ–­å¼€è¿æ¥åé‡æ–°è¿æ¥
screen -r gpu_session
# æˆ–
tmux attach -t gpu_session
```

### â“ Q3: å†…å­˜ä¸è¶³é”™è¯¯
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
top -u $USER

# è§£å†³æ–¹æ¡ˆ
1. å‡å°‘batch_size
2. ä½¿ç”¨gradient_accumulation
3. è¯·æ±‚æ›´å¤šå†…å­˜ï¼ˆ--mem=180Gï¼‰
4. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆfp16ï¼‰
```

### â“ Q4: CUDAç‰ˆæœ¬ä¸åŒ¹é…
```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi  # Driver CUDA Version
nvcc --version  # Runtime CUDA Version

# è§£å†³æ–¹æ¡ˆ
module load CUDA/11.8
# æˆ–é‡æ–°å®‰è£…åŒ¹é…çš„PyTorchç‰ˆæœ¬
```

---

## æœ€ä½³å®è·µå»ºè®®

### ğŸ¯ èµ„æºç”³è¯·ç­–ç•¥

1. **å¼€å‘è°ƒè¯•é˜¶æ®µ**
   ```bash
   ./Setup/interactive_job_gpu_debug.sh  # å¿«é€Ÿè·å¾—20åˆ†é’Ÿ
   ```

2. **é•¿æ—¶é—´å¼€å‘**
   ```bash
   ./Setup/interactive_job_gpu_preemptable.sh  # æ¨è
   ```

3. **æ­£å¼è®­ç»ƒ**
   ```bash
   sbatch your_training_script.sbatch  # æ‰¹å¤„ç†ä½œä¸š
   ```

### ğŸ“ é¡¹ç›®ç»„ç»‡å»ºè®®

```
your_project/
â”œâ”€â”€ data/                    # æ•°æ®æ–‡ä»¶
â”œâ”€â”€ src/                     # æºä»£ç 
â”œâ”€â”€ configs/                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ scripts/                 # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ train.sbatch
â”œâ”€â”€ logs/                    # SLURMæ—¥å¿—
â”œâ”€â”€ checkpoints/            # æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ results/                # å®éªŒç»“æœ
â””â”€â”€ Setup/                  # ç¯å¢ƒé…ç½®ï¼ˆæœ¬æ•™ç¨‹æä¾›çš„è„šæœ¬ï¼‰
    â”œâ”€â”€ H100.sh
    â”œâ”€â”€ interactive_job_gpu_preemptable.sh
    â””â”€â”€ GPU_Tutorial.md     # æœ¬æ•™ç¨‹
```

### âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **è®­ç»ƒä¼˜åŒ–**
   ```python
   # ä½¿ç”¨æ··åˆç²¾åº¦
   from torch.cuda.amp import autocast, GradScaler
   
   # å¯ç”¨XFormersï¼ˆå¦‚é€‚ç”¨ï¼‰
   model.enable_xformers_memory_efficient_attention()
   
   # ä¼˜åŒ–DataLoader
   DataLoader(dataset, num_workers=4, pin_memory=True)
   ```

2. **èµ„æºç›‘æ§**
   ```bash
   # å®šæœŸæ£€æŸ¥GPUä½¿ç”¨ç‡
   nvidia-smi dmon -s puc
   
   # ç›‘æ§è®­ç»ƒè¿›åº¦
   tail -f logs/training.log | grep -E "(loss|accuracy|step)"
   ```

3. **æ£€æŸ¥ç‚¹ç®¡ç†**
   ```python
   # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
   if step % 500 == 0:
       torch.save(model.state_dict(), f'checkpoint-{step}.pt')
   
   # é™åˆ¶æ£€æŸ¥ç‚¹æ•°é‡
   checkpoints_total_limit = 3
   ```

### ğŸ”’ å®‰å…¨å’Œå¤‡ä»½

```bash
# å®šæœŸå¤‡ä»½é‡è¦æ–‡ä»¶
rsync -av --progress checkpoints/ backup/checkpoints/
rsync -av --progress results/ backup/results/

# ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶
git add -A && git commit -m "Experiment checkpoint"
git push origin main
```

---

## ğŸ“ è·å–å¸®åŠ©

### ğŸ†˜ ç´§æ€¥é—®é¢˜

1. **ä»»åŠ¡å¼‚å¸¸ç»ˆæ­¢**
   ```bash
   # æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
   sacct -j <JOB_ID> --format=JobID,State,ExitCode,DerivedExitCode
   
   # æŸ¥çœ‹å®Œæ•´æ—¥å¿—
   cat logs/your_job-<JOB_ID>.err
   ```

2. **èµ„æºä½¿ç”¨å¼‚å¸¸**
   ```bash
   # è”ç³»ç®¡ç†å‘˜å‰æ”¶é›†ä¿¡æ¯
   scontrol show job <JOB_ID>
   sstat -j <JOB_ID> --format=JobID,MaxRSS,MaxVMSize,NTasks
   ```

### ğŸ“š æ›´å¤šèµ„æº

- [Ubelixå®˜æ–¹æ–‡æ¡£](https://hpc-unibe-ch.github.io/user-guide/)
- [SLURMç”¨æˆ·æŒ‡å—](https://slurm.schedmd.com/documentation.html)
- [é›†ç¾¤ä½¿ç”¨æ”¿ç­–](https://www.id.unibe.ch/hpc)

---

## ğŸ“ˆ æ›´æ–°æ—¥å¿—

- **2025-09-24**: åˆå§‹ç‰ˆæœ¬ï¼ŒåŒ…å«å®Œæ•´çš„GPUä½¿ç”¨æ•™ç¨‹
- æ¶µç›–äº¤äº’å¼ä¼šè¯ã€æ‰¹å¤„ç†ä½œä¸šã€ç›‘æ§å’Œè°ƒè¯•
- æä¾›ä¸‰ç§QoSç­–ç•¥çš„å¯¹æ¯”å’Œä½¿ç”¨å»ºè®®

---

**ğŸ’¡ æç¤º**: å»ºè®®å°†æ­¤æ•™ç¨‹åŠ å…¥ä¹¦ç­¾ï¼Œå¹¶å®šæœŸæŸ¥çœ‹æ›´æ–°ã€‚å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚